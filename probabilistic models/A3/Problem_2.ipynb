{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b37947954259d35f2fcf85ce5dea0c65",
     "grade": false,
     "grade_id": "cell-d6e49c0f3b2294e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bayesian_network import BayesNet\n",
    "from utils import sample_forward, get_default_bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f12d6681c911844a780baf4557356f3",
     "grade": false,
     "grade_id": "cell-cbf36ef06ad975a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Parameter Learning\n",
    "\n",
    "In this problem, we will assume that a fixed dependency graph structure between variables is given and learn the parameters (the complete Conditional Probability Distribution Table (CPDT)) from a set of events. Furthermore, we will use log-likelihood to find a model structure that also generalizes to future data.\n",
    "    \n",
    "## ML Estimates for Conditional Distributions\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>maximum_likelihood_estimate</i> function, which computes the Maximum Likelihood Estimate for the parameters of a discrete (conditional) probability distribution $ P(X \\mid \\mathit{pa}(X) )$, given a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`maximum_likelihood_estimate` takes  three parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `variable_id` is the column index of the variable to estimate the distribution for.\n",
    "- `parent_ids` is a tuple, containing the column indices of parent variables.\n",
    "- `alpha` is a non-negative integer, corresponding to pseudocounts in Laplace smoothing.\n",
    "\n",
    "`maximum_likelihood_estimate` must return one object:\n",
    "- A Maximum Likelihood Estimate (MLE) of the parameters in form of a `np.ndarray`. The first dimension (index `0`) of the returned array must correspond to variable `variable_id`, the remaining dimensions must be sorted according to `parent_ids`. Altogether, tuple `(variable_id, ) + parent_ids` gives the mapping of dimensions to variables.\n",
    "\n",
    "Hint:\n",
    "- Assume that all variables are boolean.\n",
    "- To count elements in a Numpy array, you simply loop over the data array.\n",
    "- The smoothing parameter `alpha` is added to the counts of each possible event represented in the CPDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08e93fc8cd23615080625ca14bbff79e",
     "grade": false,
     "grade_id": "cell-436ef56fc07b775c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def maximum_likelihood_estimate(data: np.ndarray, variable_id: int, parent_ids: tuple=tuple(), alpha: int=0):\n",
    "    \"\"\"\n",
    "    Estimates the conditional probability distribution of a (discrete) variable from data.\n",
    "    :param data:    data to estimate distribution from\n",
    "    :param variable_id:  column index corresponding to the variable we estimate the distribution for\n",
    "    :param parent_ids: column indices of the variables the distribution is conditioned on\n",
    "    :param alpha: smoothing parameter, pseudocounts\n",
    "    :returns: estimated conditional probability distribution table\n",
    "    \"\"\"\n",
    "    \n",
    "    assert type(variable_id) == int\n",
    "    assert type(parent_ids) == tuple\n",
    "    \n",
    "    # mapping of axis to variable_id,\n",
    "    # e.g. the variable with id variable_ids[i] is on axis i of the CPDT\n",
    "    variable_ids = (variable_id,) + parent_ids\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    cpdt = np.zeros([2]*(len(variable_ids)), np.float64)\n",
    "    accum = np.zeros([2]*(len(variable_ids)), np.int64)\n",
    "    #print(\"cpdt:\",cpdt.shape)\n",
    "    #print(\"accum:\",accum.shape)\n",
    "    \n",
    "    \n",
    "    for sample in data:\n",
    "        data_s = [sample[indexer] for indexer in (variable_ids)] \n",
    "        accum[tuple(data_s)] += 1\n",
    "    \n",
    "    cpdt[0] = (accum[0] + alpha) / (accum.sum(axis=0, keepdims=True)[0] + 2*alpha + 1e-10)\n",
    "    cpdt[1] = 1 - cpdt[0]\n",
    "   # print(\"cpdt:\",cpdt)\n",
    "   # diff = np.abs(expected - actual)\n",
    "    #print(\"Differences:\", diff)\n",
    "    #raise NotImplementedError()\n",
    "    \n",
    "    return cpdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e64485165c8633ae69c633bd1e3edc8a",
     "grade": true,
     "grade_id": "cell-1c8f099373bf6fc1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "_A_, _B_, _C_, _D_, _E_ = 0, 1, 2, 3, 4\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# get exact A form bayes net\n",
    "expected = bayes_net[_A_].pdt[:,0,0,0,0]\n",
    "# estimate A from the data\n",
    "actual = maximum_likelihood_estimate(data, _A_)\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.05))\n",
    "\n",
    "# get exact B_A form bayes net\n",
    "expected = bayes_net[_B_].pdt[:,:,0,0,0].T\n",
    "# estimate B_A from data\n",
    "actual = maximum_likelihood_estimate(data, _B_, (_A_,))\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.05))\n",
    "\n",
    "# test if alpha correctly added\n",
    "expected = [0.29166667, 0.70833333]\n",
    "# estimate A from the data with alpha=10\n",
    "actual = maximum_likelihood_estimate(data, _A_, alpha=10)\n",
    "# estimate should not be far off\n",
    "assert np.all(np.isclose(expected, actual, atol=0.0001))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cedffdc1886efc3d1407de536e6c4db6",
     "grade": false,
     "grade_id": "cell-266284793d5b1fa8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### The Log-Likelihood Function\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Implement the <i>log_likelihood</i> function, which computes the log-likelihood $\\mathcal{L}(\\mathcal{M} : \\mathcal{D})$ of a model (BayesNet) relative to a data set. (3 points)\n",
    "</div>\n",
    "\n",
    "`log_likelihood` takes two parameters:\n",
    "- `data` is a NumPy array of shape `(num_samples, num_variables)`.\n",
    "- `bayes_net` a BayesNet object representing the model $\\mathcal{M}$ (containing already estimated CPDTs).\n",
    "\n",
    "`log_likelihood` must return one object:\n",
    "- The log-likelihood of the model given the data (i.e., a floating point number (<= 0)).\n",
    "\n",
    "Hint:\n",
    "- Recall that iterating over the variables in the BayesNet is super easy: `for variable in bayes_net: ...`.\n",
    "- The probability distribution of variable $X$ given its parents $\\mathit{pa}(X)$, $P(X \\mid \\mathit{pa}(X))$, can be obtained by passing the random event to the variable, i.e., `variable(data[i])`.\n",
    "- Use the natural logarithm for your computations, i.e. `np.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee480429f8e2cb73da6c99354ff29bc6",
     "grade": false,
     "grade_id": "cell-05bb2766b425e4ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def log_likelihood(data: np.ndarray, bayes_net: BayesNet):\n",
    "    \"\"\"\n",
    "    Computes the log-likelihood of a given Bayesian network relative to the data.\n",
    "    :param data: data to compute the log-likelihood relative to.\n",
    "    :param bayes_net: Bayesian network model.\n",
    "    :returns: the log-likelihood of the Bayesian network relative to the data.\n",
    "    \"\"\"    \n",
    "\n",
    "    ll = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for sample in data:\n",
    "        for variable in bayes_net:\n",
    "            lk = variable(sample)[sample[variable.id]]\n",
    "            ll = ll + np.log(lk)\n",
    "  #  raise NotImplementedError()\n",
    "    \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10cb46e7d0cb2b0175e85aeabbfefbe7",
     "grade": true,
     "grade_id": "cell-fb8f52c535549516",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "# get the bayes net from the previous problem\n",
    "bayes_net = get_default_bayes_net()\n",
    "np.random.seed(0)\n",
    "# draw 100 samples\n",
    "data = sample_forward(bayes_net, 100)\n",
    "\n",
    "# expected log-likelihood\n",
    "expected = -215.9\n",
    "# actual log-likelihood\n",
    "actual = log_likelihood(data, bayes_net)\n",
    "\n",
    "# must be close\n",
    "assert np.all(np.isclose(expected, actual, atol=0.1))\n",
    "\n",
    "\n",
    "# remove unused variables\n",
    "del data\n",
    "del bayes_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "da19792956cd8484de125e18621651c2",
     "grade": false,
     "grade_id": "cell-46024e03394db093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding a Model for Strokes   \n",
    "\n",
    "After watching hours of medical dramas on television, you try to figure out the perfect prediction model for strokes. Some of your computer science colleagues told you about how Bayesian networks can be used for symptom diagnosis, so you decide to model your ideas using this technique. \n",
    "\n",
    "Let's assume that you magically know the true underlying Bayes model (structure and parameters); all variables in this example are boolean (false=0 or true=1).  \n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod2.svg\">\n",
    "\n",
    "The conditional probability tables are given as follows:\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>-</td><td>0.01</td><td>0.99</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(H | A)</th><th>$a_0$<br></th><th>$a_1$</th></tr><tr><td>$h_0$</td><td>0.9</td><td>0.8</td></tr><tr><td>$h_1$</td><td>0.1</td><td>0.2</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(S | H)</th><th>$h_0$<br></th><th>$h_1$</th></tr><tr><td>$s_0$</td><td>0.9</td><td>0.85</td></tr><tr><td>$s_1$</td><td>0.1</td><td>0.15</td></tr></table>\n",
    "\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th rowspan=\"2\">P(C | A, S)</th><th colspan=\"2\">$a_0$<br></th><th colspan=\"2\">$a_1$</th></tr><tr><td>$s_0$</td><td>$s_1$</td><td>$s_0$</td><td>$s_1$</td></tr><tr><td>$c_0$<br></td><td>0.8</td><td>0.7</td><td>0.85</td><td>0.45</td></tr><tr><td>$c_1$</td><td>0.2</td><td>0.3</td><td>0.15</td><td>0.55</td></tr></table>\n",
    "\n",
    "<table style=\"float: left;margin:5px;\"><tr><th>P(V | S)</th><th>$s_0$</th><th>$s_1$</th></tr><tr><td>$v_0$</td><td>0.1</td><td>0.2</td></tr><tr><td>$v_1$</td><td>0.9</td><td>0.8</td></tr></table>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7f49c7805956098e38a9b9b94c56929",
     "grade": false,
     "grade_id": "cell-2e0a9f7bef60a27e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to find a good model, you would need to collect a lot of training examples.\n",
    "\n",
    "But since we know the true undelying model, you can instead just sample 5000 events from this network as the training data, and 5000 samples as the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0a771d23aaec82b53deb33258d4ea82",
     "grade": false,
     "grade_id": "cell-4c0f9e2cac1e27af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "A = np.array([0.01, 0.99])\n",
    "H_A = np.array([[0.9, 0.8], [0.1, 0.2]])\n",
    "S_H = np.array([[0.9, 0.85], [0.1, 0.15]])\n",
    "C_AS = np.array([[[0.8, 0.7], [0.85, 0.45]], [[0.2, 0.3], [0.15, 0.55]]])\n",
    "V_S = np.array([[0.1, 0.2], [0.9, 0.8]])\n",
    "\n",
    "# this bayes net represents the true underlying full joint distribution in the medical world \n",
    "true_bayes_net = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_H, (_S_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_S, (_V_,_S_))\n",
    ")\n",
    "np.random.seed(0)\n",
    "train = sample_forward(true_bayes_net, 5000)\n",
    "test = sample_forward(true_bayes_net, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "459c15ec9089733c14868e31c0435cfe",
     "grade": false,
     "grade_id": "cell-461bf6d16acbfa3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for the true underlying network structure and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "  \n",
    "  \n",
    "Store the CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34703c76c2900f4125d1e0b31852e752",
     "grade": false,
     "grade_id": "cell-adce166a4d080cf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H_A, S_H, C_AS, V_S = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "A = maximum_likelihood_estimate(train, _A_)\n",
    "H_A = maximum_likelihood_estimate(train, _H_, (_A_,))\n",
    "S_H = maximum_likelihood_estimate(train, _S_, (_A_,))\n",
    "C_AS = maximum_likelihood_estimate(train, _C_, (_A_, _S_))\n",
    "V_S = maximum_likelihood_estimate(train, _V_, (_S_,))\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H_A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S_H.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C_AS.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V_S.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_1 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_H, (_S_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_S, (_V_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_1 = 0\n",
    "\n",
    "# YOUR CODE HERe\n",
    "tr_log_likelihood_1 = log_likelihood(train, bayes_net_1)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "918dcd10a1ae90d0bc22830499e3de6e",
     "grade": true,
     "grade_id": "cell-aee49c763a9fe1a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_1 < -8500\n",
    "assert tr_log_likelihood_1 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2393bddc509932735cd176b77944eca1",
     "grade": false,
     "grade_id": "cell-262f7422251f2622",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Back to our strokes model: Having no idea of the true underlying network structure, you decide to try out the following very simple model first:\n",
    "    \n",
    "<img style='width:100%;  max-width:400px;' src=\"img/bn_mod1.svg\">\n",
    "\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for this model and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the CPDTs into the provided variables.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e419893d0128bfe05a9abe6e7415328",
     "grade": false,
     "grade_id": "cell-11b996647bc6f74c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H, S, C, V = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "A = maximum_likelihood_estimate(train, _A_)\n",
    "H = maximum_likelihood_estimate(train, _H_)\n",
    "S = maximum_likelihood_estimate(train, _S_)\n",
    "C = maximum_likelihood_estimate(train, _C_)\n",
    "V = maximum_likelihood_estimate(train, _V_)\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_2 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H, (_H_,)),\n",
    "    (S, (_S_,)),\n",
    "    (C, (_C_,)),\n",
    "    (V, (_V_,))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_2 = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tr_log_likelihood_2 = log_likelihood(train, bayes_net_2)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4b8bd563930aaaadc2b9083539df8a8",
     "grade": true,
     "grade_id": "cell-b30990c4827845f9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_2 < -8500\n",
    "assert tr_log_likelihood_2 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0c6ae1d70483dc96759881859f8a634",
     "grade": false,
     "grade_id": "cell-d0193730bdfc314d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "Unhappy with the result, you decide to try out a second, more complex model:\n",
    "\n",
    "<img  style='width:100%;  max-width:400px;' src=\"img/bn_mod3.svg\">\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Based on the sampled training data points, estimate the (conditional) probability tables for this model and compute its log-likelihood w.r.t the training data. (1 point)\n",
    "</div>\n",
    "\n",
    "Store the CPDTs into the provided variables. The dimensions of the CPDT must be sorted according to the naming of the variable, e.g., in C_AS, dimension 0 corresponds to C, dimension 1 to A, and dimension 2 to S.\n",
    "\n",
    "**Hint**:\n",
    "- Use the two functions you implemented above (`maximum_likelihood_estimate` and `log_likelihood`)!\n",
    "- The training data is stored in variable `train`. \n",
    "- `_A_, _H_, _S_, _C_, _V_` hold the column indices (= IDs) of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36794cfa03210bd015bb0528213caa23",
     "grade": false,
     "grade_id": "cell-385934a752ed9259",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "_A_, _H_, _S_, _C_, _V_ = 0, 1, 2, 3, 4\n",
    "\n",
    "A, H_A, S_AH, C_AS, V_CS = None, None, None, None, None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "A = maximum_likelihood_estimate(train, _A_)\n",
    "H_A = maximum_likelihood_estimate(train, _H_, (_A_,))\n",
    "S_AH = maximum_likelihood_estimate(train, _S_, (_A_,_H_))\n",
    "C_AS = maximum_likelihood_estimate(train, _C_, (_A_, _S_))\n",
    "V_CS = maximum_likelihood_estimate(train, _V_, (_C_,_S_))\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# begin sanity check\n",
    "assert np.all(np.isclose(A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(H_A.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(S_AH.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(C_AS.sum(axis=0), 1))\n",
    "assert np.all(np.isclose(V_CS.sum(axis=0), 1))\n",
    "# end sanity check\n",
    "\n",
    "bayes_net_3 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_AH, (_S_,_A_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_CS, (_V_,_C_,_S_))\n",
    ")\n",
    "\n",
    "tr_log_likelihood_3 = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "tr_log_likelihood_3 = log_likelihood(train, bayes_net_3)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0745ab2383ea7481c0124edd4c68cd3a",
     "grade": true,
     "grade_id": "cell-0847b76132961219",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert tr_log_likelihood_3 < -8500\n",
    "assert tr_log_likelihood_3 > -8800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4a47de1161e05ec4d2536c5891e5d90",
     "grade": false,
     "grade_id": "cell-60eaec1dda1e7b09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Train Log-Likelihoods\n",
    "\n",
    "Compare the log-likelihoods w.r.t the training data of Model **M1** (having the true underlying structure) to the two new models (**M2** - no edges, **M3** - complex model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae46f32357d5c58a722e4046bf08c6f0",
     "grade": false,
     "grade_id": "cell-14898c94ac010e16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(train|M1) = -8613.374837357533\n",
      "logP(train|M2) = -8740.033479009893\n",
      "logP(train|M3) = -8504.427454360319\n"
     ]
    }
   ],
   "source": [
    "print('logP(train|M1) = {}'.format(tr_log_likelihood_1))\n",
    "print('logP(train|M2) = {}'.format(tr_log_likelihood_2))\n",
    "print('logP(train|M3) = {}'.format(tr_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f3d168c63f1925ef3830ddedcb83a1d",
     "grade": false,
     "grade_id": "cell-c6cc8633bf6db812",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question in one sentence! (1 point)\n",
    "</div>\n",
    "\n",
    "Even though **M1** has the true underlying network structure (it correctly represents all independencies holding in our world), it doesn't have the highest train log-likelihood. How do you explain this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be344344394f67f5fe02c21d744f98f0",
     "grade": true,
     "grade_id": "cell-f239713a903eec15",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE.\n",
    "\n",
    "M2 and M3 have higher log-likelihood due to the higher flixibelity and more potentiialy the overfitting to the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd2f2499bbbce42c077b6faffd9e5b08",
     "grade": false,
     "grade_id": "cell-913efb638a138834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Compare Test Log-Likelihoods\n",
    "\n",
    "Finally, we compute the test log-likelihood of the model **M1** (having the true underlying structure) and the newly created models **M2** and **M3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce2d838d52c5ec2698eecbf58224ce14",
     "grade": false,
     "grade_id": "cell-7405d51a161fef12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP(test|M1) = -8492.78914241468\n",
      "logP(test|M2) = -8598.449646741794\n",
      "logP(test|M3) = -8379.468463963667\n"
     ]
    }
   ],
   "source": [
    "te_log_likelihood_1 = log_likelihood(test, bayes_net_1)\n",
    "te_log_likelihood_2 = log_likelihood(test, bayes_net_2)\n",
    "te_log_likelihood_3 = log_likelihood(test, bayes_net_3)\n",
    "\n",
    "print('logP(test|M1) = {}'.format(te_log_likelihood_1))\n",
    "print('logP(test|M2) = {}'.format(te_log_likelihood_2))\n",
    "print('logP(test|M3) = {}'.format(te_log_likelihood_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b3f8f0b7221f84f4b0e4dc5838584bc",
     "grade": false,
     "grade_id": "cell-305b267f209685e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question! Keep your answers short! (1 point)\n",
    "</div>\n",
    "\n",
    "What is the difference compared the the log-likelihoods of the training data? Explain the difference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d059bd7ea2f45258367e174a11b3d48c",
     "grade": true,
     "grade_id": "cell-b53213b16dfb15f6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "the diffrence mainly is in the complexity of the model also overfitting because some models revise pst data rather than generaliz it so leading to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3be3187cdfc89852d5ccdf4d24b89eb3",
     "grade": false,
     "grade_id": "cell-513dda62c8ee6d5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Laplace Smoothing\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    Answer the following question! Keep your answer short! (1 point)\n",
    "</div>\n",
    "\n",
    "Estimate the (conditional) probability tables for your model **M3** again. However, this time you only have a training set consisting of 100 samples. You run into the error shown in the output of the code cell below. Explain the source of the problem and how to avoid it by adapting a parameter when calling the function ```maximum_likelihood_estimate```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52567a2a99156b1ec48da9aa7d140464",
     "grade": true,
     "grade_id": "cell-256e320984be291c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "the main problem is that the data set is too small to cover all the possible combinations leading to a zero value for those remaining combinations so missnormalizatoin, and to solve that we have to ada a smoothing factor (alpha) to make sure that all the missed combination have a value not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "# we generate a new training set consisting of 100 samples\n",
    "train = sample_forward(true_bayes_net, 100)  \n",
    "\n",
    "A = maximum_likelihood_estimate(train, _A_)\n",
    "H_A = maximum_likelihood_estimate(train, _H_, (_A_,))\n",
    "S_AH = maximum_likelihood_estimate(train, _S_, (_A_, _H_,))\n",
    "C_AS = maximum_likelihood_estimate(train, _C_, (_A_, _S_))\n",
    "V_CS = maximum_likelihood_estimate(train, _V_, (_S_,_C_,))\n",
    "\n",
    "bayes_net_3 = BayesNet(\n",
    "    (A, (_A_,)),\n",
    "    (H_A, (_H_,_A_)),\n",
    "    (S_AH, (_S_,_A_,_H_)),\n",
    "    (C_AS, (_C_,_A_,_S_)),\n",
    "    (V_CS, (_V_,_C_,_S_))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
